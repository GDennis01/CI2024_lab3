{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple,defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import heapq\n",
    "import icecream as ic\n",
    "import functools\n",
    "from typing import Any\n",
    "from typing_extensions import Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(fn):\n",
    "    \"\"\"Simple decorator for counting number of calls\"\"\"\n",
    "\n",
    "    @functools.wraps(fn)\n",
    "    def helper(*args, **kargs):\n",
    "        helper.calls += 1\n",
    "        return fn(*args, **kargs)\n",
    "\n",
    "    helper.calls = 0\n",
    "    return helper\n",
    "\n",
    "@counter\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "@counter\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "def is_solvable(state:np.ndarray)->bool:\n",
    "    inv_count = 0\n",
    "    tmp_state = state.copy().reshape(PUZZLE_DIM**2)\n",
    "    for i in range(0,PUZZLE_DIM**2):\n",
    "        for j in range(i+1,PUZZLE_DIM**2):\n",
    "            if tmp_state[j] != 0 and tmp_state[i] != 0 and tmp_state[i] > tmp_state[j]:\n",
    "                inv_count += 1\n",
    "    return (inv_count%2) == 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self,matrix:np.ndarray):\n",
    "        self.matrix = matrix\n",
    "        self.f=float('inf')\n",
    "        self.g=float('inf')\n",
    "        self.h =float('inf')\n",
    "    # Dunder methods so that we can use State as a proper key in a dictionary/set\n",
    "    def __str__(self):\n",
    "        return self.matrix.__str__()\n",
    "    def __repr__(self) -> str:\n",
    "        return self.matrix.__str__()+f'\\nf:{self.f} g:{self.g} h:{self.h}\\n'\n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "    def __eq__(self, value: object) -> bool:\n",
    "        if isinstance(value,State):\n",
    "            return self.__str__() == value.__str__()\n",
    "        return NotImplemented\n",
    "    def __lt__(self,other):\n",
    "        return self.f < other.f\n",
    "    \n",
    "    def is_solvable(self)->bool:\n",
    "        inv_count = 0\n",
    "        tmp_state = self.matrix.copy().reshape(PUZZLE_DIM**2)\n",
    "        for i in range(0,PUZZLE_DIM**2):\n",
    "            for j in range(i+1,PUZZLE_DIM**2):\n",
    "                if tmp_state[j] != 0 and tmp_state[i] != 0 and tmp_state[i] > tmp_state[j]:\n",
    "                    inv_count += 1\n",
    "        return (inv_count%2) == 0 \n",
    "    def is_goal(self)-> bool:\n",
    "        tmp = self.matrix.copy().reshape(PUZZLE_DIM**2)\n",
    "        for (i,e) in enumerate(tmp):\n",
    "            if i+1 != e and e != 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_neighbours(self)->list[Self]:\n",
    "        neigh = [State(do_action(self.matrix,a)) for a in  available_actions(self.matrix)]\n",
    "        return neigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic and Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toop_heuristic(state:State,goal_state:State)->int:\n",
    "    \"\"\"\n",
    "    Computing the tiles-out-of-place heuristic.\n",
    "    state: State of the n-puzzle game\n",
    "    goal_state: Desired goal state of the n-puzzle game\n",
    "    \"\"\"\n",
    "    print(\"a\")\n",
    "    tmp_state = state.matrix.reshape(PUZZLE_DIM**2)\n",
    "    tmp_goal = goal_state.matrix.reshape(PUZZLE_DIM**2)\n",
    "    tmp = tmp_goal!=tmp_state\n",
    "    return tmp.sum()-1\n",
    "\n",
    "def manhattan_heuristic(state:State,goal_state:State)->int:\n",
    "    distance = 0\n",
    "    for elem in range(1,PUZZLE_DIM**2):\n",
    "        start_coords = np.where(state.matrix == elem)\n",
    "        end_coords = np.where(goal_state.matrix == elem)\n",
    "        distance+=  abs(start_coords[0]-end_coords[0])+abs(start_coords[1]-end_coords[1])\n",
    "    return distance\n",
    "                \n",
    "\n",
    "def get_lowest_node(open_set:list[State],f_score)->State:\n",
    "    \"\"\"\n",
    "    Retrieves the node with the lowest f_score. It replaces the priority queue\n",
    "    open_set: list with all nodes to explore\n",
    "    f_score: dictionary containing nodes with their respective f score where f(n) is g(n) + h(n)\n",
    "    \"\"\"\n",
    "    sorted_os = sorted(open_set,key=lambda e:f_score[e])\n",
    "    return sorted_os[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def A_star(initial_state:State,goal_state:State,heuristic=manhattan_heuristic)->State:\n",
    "    open_set:list[State] = []\n",
    "\n",
    "    closed_list:set[State] = set()\n",
    "    initial_state.f = 0\n",
    "    # With priority queue\n",
    "    heapq.heappush(open_set,initial_state)\n",
    "\n",
    "    #Without priority queue\n",
    "    # open_set=[initial_state]\n",
    "\n",
    "    # g[n] is the cost(number of movements) from initial_state from n\n",
    "    g_score = defaultdict(lambda:float('inf'),dict())\n",
    "    g_score[initial_state] = 0\n",
    "    # f[n] is the cost from start to goal state accordin to our heuristic-> f(n) = g(n)+h(n)\n",
    "    f_score = defaultdict(lambda:float('inf'),dict())\n",
    "    f_score[initial_state] = heuristic(initial_state,goal_state)\n",
    "    i=0\n",
    "    while len(open_set) != 0:\n",
    "        # With priority queue\n",
    "        current = heapq.heappop(open_set)\n",
    "        closed_list.add(current)\n",
    "\n",
    "        # Without Priority Queue\n",
    "        # current = get_lowest_node(open_set,f_score)\n",
    "        # current.h = heuristic(current,goal_state)\n",
    "        # open_set.remove(current)\n",
    "\n",
    "        if current.is_goal():\n",
    "            print(f'Closed list len:{len(closed_list)}')\n",
    "            return current,i\n",
    "        for neighbour in current.get_neighbours():\n",
    "            tentative_gscore = g_score[current]+1\n",
    "            if tentative_gscore < g_score[neighbour]:\n",
    "                g_score[neighbour] = tentative_gscore\n",
    "                neighbour.g = g_score[neighbour]\n",
    "                neighbour.h = heuristic(neighbour,goal_state)\n",
    "                f_score[neighbour] = tentative_gscore + neighbour.h\n",
    "                neighbour.f = f_score[neighbour]\n",
    "                # if neighbour not in open_set:\n",
    "                if neighbour not in closed_list:\n",
    "                    # With priority queue\n",
    "\n",
    "                    heapq.heappush(open_set,neighbour)\n",
    "                    \n",
    "                    # Without priority queue\n",
    "                    # open_set.append(neighbour)\n",
    "                    \n",
    "        i+=1\n",
    "    \n",
    "    return np.array([0]),i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbce9b69adb4a1b80e0f056be1d4e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state:\n",
      "[[0 2 1]\n",
      " [3 7 5]\n",
      " [8 6 4]]\n",
      "Closed list len:662\n",
      "Found solution: \n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]] \n",
      "with 22 actions taken(quality) and 666 nodes evaluated(cost)\n"
     ]
    }
   ],
   "source": [
    "# Creating a valid problem starting from the solution\n",
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, random.choice(available_actions(state)))\n",
    "state = state.reshape(PUZZLE_DIM,PUZZLE_DIM)\n",
    "\n",
    "# Easy solvable n-puzzle problem useful for testing purposes.  PUZZLE_DIM = 3. For an A* the solving time should be instant\n",
    "# state = np.array([np.array([1,8,2]),np.array([0,4,3]),np.array([7,6,5])]). \n",
    "\n",
    "# Hard solvable n-puzzle problem useful for testing purposes.  PUZZLE_DIM = 3. For an A* the solving time should be around 20 sec-ish\n",
    "state = np.array([np.array([0,2,1]),np.array([3,7,5]),np.array([8,6,4])])\n",
    "\n",
    "# Almost impossible solvable n-puzzle problem with PUZZLE_DIM = 5\n",
    "# state = np.array([[13,  9,  0, 10, 19],\n",
    "#                            [ 3, 21, 14,  5,  8],\n",
    "#                            [22, 16,  4, 24, 18],\n",
    "#                            [ 6,  2, 11,  1, 20],\n",
    "#                            [ 7, 15,23,12,17]])\n",
    "print(f'Starting state:\\n{state}')\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM,PUZZLE_DIM))\n",
    "\n",
    "# Applying A_star on the randomized problem\n",
    "solution,i = A_star(State(state),State(goal_state),manhattan_heuristic)\n",
    "# i is equal to  number of times get_neighbours/available_actions function is called\n",
    "print(f'Found solution: \\n{solution} \\nwith {solution.g} actions taken(quality) and {i} nodes evaluated(cost)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENVLAB3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
